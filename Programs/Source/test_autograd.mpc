from tensor import Tensor,autograd_function
import tensor
import functional as F
from Compiler.types import *
program.options_from_args()

sfix.set_precision(30, 60)
cfix.set_precision(30, 60)

@autograd_function
def test_mul():
    print_ln('test_mul_input: ')
    x = MultiArray([3, 2, 3], sfix)
    for i in range(x.total_size()):
        x.assign_vector(sfix(i), i)
    x.print_reveal_nested()
    y = MultiArray([2, 1], cint)
    y.assign_all(5)
    y[0][0]=6
    y.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input2 = Tensor(y, req_grad = False)

    input3 = input1 * input2

    tensor.train()
    tensor.reset_op_id()

    print_ln('test_mul_output: ')
    input3 = input1 * input2
    input3.value.print_reveal_nested()
    input3.backward()

    print_ln('test_mul_backward: ')
    input1.grad.print_reveal_nested()
    #input2.grad.print_reveal_nested()
    
def test_single_operation(func,Value):
    Value.print_reveal_nested()
    input = Tensor(Value, req_grad = True)
    output = getattr(input, func)() 
    tensor.train()
    tensor.reset_op_id()

    input3 = input1 *input2
    input3.value.print_reveal_nested()
    input3.backward()
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()

@autograd_function
def test_add():
    print_ln('test_add_input: ')
    x = MultiArray([3, 2, 3], sfix)
    for i in range(x.total_size()):
        x.assign_vector(sfix(i), i)
    x.print_reveal_nested()
    y = MultiArray([2, 1], sfix)
    y.assign_all(5)
    y[0][0]=6
    y.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input2 = Tensor(y, req_grad = True)

    input3 = input1 +input2

    tensor.train()
    tensor.reset_op_id()

    print_ln('test_add_output: ')
    input3 = input1 +input2
    input3.value.print_reveal_nested()
    input3.backward()
    print_ln('test_add_backward: ')
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()

@autograd_function
def test_sub():
    print_ln('test_sub_input: ')
    x = MultiArray([3, 3, 2], sfix)
    x.assign_all(1)
    x.print_reveal_nested()
    y = MultiArray([1, 2], sfix)
    y.assign_all(5)
    y[0][0]=6
    y.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input2 = Tensor(y, req_grad = True)

    input3 = input1 - input2

    tensor.train()
    tensor.reset_op_id()

    print_ln('test_sub_output: ')
    input3 = input1 - input2
    input3.value.print_reveal_nested()
    input3.backward()
    print_ln('test_sub_backward: ')
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()

@autograd_function
def test_div():
    print_ln('test_div_input: ')
    x = MultiArray([2, 2, 2, 2], sfix)
    y = MultiArray([1, 2, 1, 1], sfix)
    xx = [[[[-0.0150, -0.0050],
          [-0.0050,  0.0050]],

         [[-0.0162, -0.0062],
          [-0.0062,  0.0038]]],


        [[[-0.0050,  0.0050],
          [ 0.0050,  0.0150]],

         [[-0.0062,  0.0038],
          [ 0.0038,  0.0238]]]]
    yy = [[[[0.0093]],

         [[0.0119]]]]
    for i in range(0,2):
        for j in range(0,2):
            for k in range(0,2):
                for l in range(0,2):
                    x[i][j][k][l] = sfix(xx[i][j][k][l])
    for i in range(0,1):
        for j in range(0,2):
            for k in range(0,1):
                for l in range(0,1):
                    y[i][j][k][l] = sfix(yy[i][j][k][l])
    x.print_reveal_nested()
    y.print_reveal_nested()

    input1 = Tensor(x, req_grad = True)
    input2 = Tensor(y, req_grad = True)

    input3 = input1 / input2

    tensor.train()
    tensor.reset_op_id()

    print_ln('test_div_output: ')
    input3 = input1 / input2
    input3.value.print_reveal_nested()
    input3.backward()
    print_ln('test_div_backward: ')
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()

@autograd_function
def test_abs():
    print_ln('test_abs')
    x = MultiArray([3, 3], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i-j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input2 = input1.abs()
    tensor.train()
    tensor.reset_op_id()
    input2 = input1.abs()
    input2.value.print_reveal_nested()
    input2.backward()
    input1.grad.print_reveal_nested()

@autograd_function
def test_argmax(dim):
    print_ln('test_argmax')
    i, j = 5, 5
    x = MultiArray([i, j], sfix)
    for i in range(0,5):
        for  j in range(0,5):
            x[i][j] = sfix((i*17+j*11)%5)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.argmax(dim=dim)

    tensor.train()
    tensor.reset_op_id()

    input2.value.print_reveal_nested()

@autograd_function
def test_combine():
    print_ln('test_combine')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i-j)
    xMultiArray_2_1 = MultiArray([3, 3], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            xMultiArray_2_1[i][j] = sfix(2)
    x.print_reveal_nested()
    xMultiArray_2_1.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input0 = Tensor(xMultiArray_2_1, req_grad = True)
    input8 = input1 * input0
    input2 = input8.abs()
    input3 = input2.exp()
    input4 = input3.mean()
    tensor.train()

    tensor.reset_op_id()
    input8 =  input1 * input0 
    input8.value.print_reveal_nested()
    input2 = input8.abs()
    input2.value.print_reveal_nested()
    input3 = input2.exp()
    input3.value.print_reveal_nested()
    input4 = input3.mean()
    input4.value.print_reveal_nested()    
    input4.backward()
    input1.grad.print_reveal_nested()
    input8.grad.print_reveal_nested()    
    input2.grad.print_reveal_nested()
    input3.grad.print_reveal_nested()

@autograd_function
def test_exp():
    print_ln('test_exp')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.exp()

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.exp()
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_log():
    print_ln('test_log')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.log()

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.log()
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_pow(pow):
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.pow(pow)

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.pow(pow)
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_invsqrt():
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.invsqrt()

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.invsqrt()
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_sum(dim, keepdim=False):
    print_ln('test_sum')
    x = MultiArray([3, 3, 3, 3], sfix)
    for i in range(0,3):
        for j in range(0,3):
            for k in range(0, 3):
                for q in range(0, 3):
                    x[i][j][k][q] = sfix((i*j*k*q+i+j+k+q)*1e-2)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.sum(dim, keepdim)

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.sum(dim, keepdim)
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_mean(dim, keepdim=False):
    print_ln('test_mean')
    x = MultiArray([2, 2, 2, 2], sfix)
    for i in range(0,2):
        for j in range(0,2):
            for k in range(0, 2):
                for q in range(0, 2):
                    x[i][j][k][q] = sfix( ((i*j*k*q+i+j+k+q)%101)*1e-2)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    
    v = MultiArray([1, 2, 1, 1], sfix)
    for i in range(0,1):
        for j in range(0,2):
            for k in range(0, 1):
                for q in range(0, 1):
                    v[i][j][k][q] = sfix(i+j*10+k+q*17)
    v.assign_vector(sfix(-2100.0002), 0)
    v.assign_vector(sfix(-3721.5188), 1)
    v.print_reveal_nested()
    vec = Tensor(v, req_grad = True)

    input2 = input1.std(dim, keepdim) * vec

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.std(dim, keepdim) * vec
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_var(dim, keepdim=False):
    print_ln('test_var')
    x = MultiArray([3, 3, 3, 3], sfix)
    for i in range(0,3):
        for j in range(0,3):
            for k in range(0, 3):
                for q in range(0, 3):
                    x[i][j][k][q] = sfix((i*j*k*q+i+j+k+q)*1e-2)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.var(dim, keepdim)

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.var(dim, keepdim)
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_std(dim, keepdim=False):
    print_ln('test_std')
    x = MultiArray([2,2,2,2], sfix)
    for i in range(0,2):
        for j in range(0,2):
            for k in range(0, 2):
                for q in range(0, 2):
                    x[i][j][k][q] = sfix((i*j*k*q+i+j+k+q)%101*1e-2)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.std(dim, keepdim)

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.std(dim, keepdim)
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_addc():
    print_ln('test_addc')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1 + 1

    tensor.train()
    tensor.reset_op_id()

    input2 = input1 + 1
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_subc():
    print_ln('test_subc')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1 - 1

    tensor.train()
    tensor.reset_op_id()

    input2 = input1 - 1
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_mulc():
    print_ln('test_mulc')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1 * 2

    tensor.train()
    tensor.reset_op_id()

    input2 = input1 * 2
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_divc():
    print_ln('test_divc')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1 / 2

    tensor.train()
    tensor.reset_op_id()

    input2 = input1 / 2
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_neg():
    print_ln('test_neg')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = -input1

    tensor.train()
    tensor.reset_op_id()

    input2 = -input1
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_f_droupout(p):
    print_ln('test_droupout')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,i):
        for  j in range(0,j):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = F.dropout(input1, p=p, training=True)

    tensor.train()
    tensor.reset_op_id()

    input2 = F.dropout(input1, p=p, training=True)
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_f_batchnorm():
    print_ln('test_batchnorm')
    x = MultiArray([2,2,2,2], sfix)
    for i in range(0,2):
        for j in range(0,2):
            for k in range(0, 2):
                for q in range(0, 2):
                    x[i][j][k][q] = sfix(((i*j*k*q+i+j+k+q)%101)*1e-2)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    w, b = Array(2, sfix), Array(2, sfix)
    w.assign_all(1)
    W = Tensor(w, req_grad = True)
    B = Tensor(b, req_grad = True)
    mean, std = Array(2, sfix), Array(2, sfix)
    M = Tensor(mean, req_grad = False)
    S = Tensor(std, req_grad = False)
    input2 = F.batch_norm(input1, running_mean = M, running_var = S, 
                          weight=W, bias=B, training=True)

    v = MultiArray([2,2,2,2], sfix)
    for i in range(0,2):
        for j in range(0,2):
            for k in range(0, 2):
                for q in range(0, 2):
                    v[i][j][k][q] = sfix((i+j+k+q))
    vec = Tensor(v, req_grad = True)
    input4 = input2 * vec 

    tensor.train()
    tensor.reset_op_id()

    input2 = F.batch_norm(input1, running_mean = M, running_var = S, 
                          weight=W, bias=B, training=True)
    input4 = input2 * vec

    input4.backward()
    
    
    print_ln('xhat_batchnorm_output: ')
    input2.value.print_reveal_nested()
    print_ln('xhat_batchnorm_backward: ')
    input2.grad.print_reveal_nested()
    
    
    print_ln('x_batchnorm_backward: ')
    input1.grad.print_reveal_nested()

@autograd_function
def test_f_layernorm():
    print_ln('test_layernorm')
    x = MultiArray([2,2,2,2], sfix)
    for i in range(0,2):
        for j in range(0,2):
            for k in range(0, 2):
                for q in range(0, 2):
                    x[i][j][k][q] = sfix(((i*j*k*q+i+j+k+q)%101)*1e-2)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    w, b = Array(1, sfix), Array(1, sfix)
    w[0], b[0] = sfix(1), sfix(0)
    W = Tensor(w, req_grad = True)
    B = Tensor(b, req_grad = True)
    
    input2 = F.layer_norm(input1, normalized_shape=[2,2], weight=W, bias=B)

    v = MultiArray([2,2,2,2], sfix)
    for i in range(0,2):
        for j in range(0,2):
            for k in range(0, 2):
                for q in range(0, 2):
                    v[i][j][k][q] = sfix((i+j+k+q))
    vec = Tensor(v, req_grad = True)
    input4 = input2 * vec 

    tensor.train()
    tensor.reset_op_id()

    input2 = F.layer_norm(input1, normalized_shape=[2,2], weight=W, bias=B)
    input4 = input2 * vec

    input4.backward()
    
    
    print_ln('xhat_layernorm_output: ')
    input2.value.print_reveal_nested()
    print_ln('xhat_layernorm_backward: ')
    input2.grad.print_reveal_nested()
    
    
    print_ln('x_layernorm_backward: ')
    input1.grad.print_reveal_nested()

@autograd_function
def test_f_mseloss():
    print_ln('test_f_mseloss')
    
    dims = [3, 3]

    y = MultiArray(dims, sfix)
    for i in range(dims[0]):
        for j in range(dims[1]):
            y[i][j] = sfix(i+j)
    y.print_reveal_nested()
    Y = Tensor(y, req_grad = True)

    x = MultiArray(dims, sfix)
    for i in range(dims[0]):
        for j in range(dims[1]):
            x[i][j] = sfix(i*j)
    x.print_reveal_nested()
    label = Tensor(x, req_grad = False)
    
    loss = F.mse_loss(Y, label)

    tensor.train()
    tensor.reset_op_id()

    loss = F.mse_loss(Y, label)
    loss.backward()
    loss.value.print_reveal_nested()
    Y.grad.print_reveal_nested()

@autograd_function
def test_f_normalize(p, dim=1):
    print_ln('test_f_normlize')
    
    dims = [3, 3]

    x = MultiArray(dims, sfix)
    for i in range(dims[0]):
        for j in range(dims[1]):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    X = Tensor(x, req_grad = True)
    
    loss = F.normalize(X, p, dim)

    tensor.train()
    tensor.reset_op_id()

    loss = F.normalize(X, p, dim)
    loss.backward()
    loss.value.print_reveal_nested()
    X.grad.print_reveal_nested()

@autograd_function
def test_f_cossim():
    print_ln('test_f_cossim')
    
    dims = [3, 3]

    y = MultiArray(dims, sfix)
    for i in range(dims[0]):
        for j in range(dims[1]):
            y[i][j] = sfix(i+j)
    y.print_reveal_nested()
    Y = Tensor(y, req_grad = True)

    x = MultiArray(dims, sfix)
    for i in range(dims[0]):
        for j in range(dims[1]):
            x[i][j] = sfix(i*j)
    x.print_reveal_nested()
    label = Tensor(x, req_grad = False)
    
    loss = F.cosine_similarity(Y, label)

    tensor.train()
    tensor.reset_op_id()

    loss = F.cosine_similarity(Y, label)
    loss.backward()
    loss.value.print_reveal_nested()
    Y.grad.print_reveal_nested()

@autograd_function
def test_f_gelu():
    print_ln('test_gelu')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i-j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = F.gelu(input1, approximate='tanh')

    tensor.train()
    tensor.reset_op_id()

    input2 = F.gelu(input1, approximate='tanh')
    #input2.backward()
    input2.value.print_reveal_nested()
    #input1.grad.print_reveal_nested()

@autograd_function
def test_flatten():
    print_ln('test_flatten')
    x = MultiArray([5, 4,3,2], sfix)
    for i in range(x.total_size()):
        x.assign_vector(sfix(i), i)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.flatten(1,2)

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.flatten(1,2)
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_gather():
    print_ln('test_gather')
    x = MultiArray([3,3], sfix)
    for i in range(x.total_size()):
        x.assign_vector(sfix(i+3), i)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    index = MultiArray([1,3], cint)
    for i in range(index.total_size()):
        if i == 2:
            index.assign_vector(cint(0), i)
        elif i == 0:
            index.assign_vector(cint(2), i)
        else:
            index.assign_vector(cint(i), i)
    index = Tensor(index)
    input2 = input1.gather(0,index)

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.gather(0,index)
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_expand():
    print_ln('test_expand')
    x = MultiArray([1, 3], sfix)
    for i in range(0,1):
        for  j in range(0,3):
            x[i][j] = sfix(i-j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.expand([3,3])

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.expand([3,3])
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_masked_fill_():
    print_ln('test_masked_fill_')
    x = MultiArray([3, 3], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i-j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    mask = MultiArray([3, 3], cint)
    for i in range(0,3):
        for  j in range(0,3):
            mask[i][j] = cint((i-j)%2)
    mask.print_reveal_nested()
    M = Tensor(mask, req_grad = False)

    value = MultiArray([3, 3], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            value[i][j] = i+j
    value.print_reveal_nested()
    V = Tensor(value, req_grad = False)

    input2 = input1.masked_fill_(M, V)

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.masked_fill_(M, V)
    #input2.backward()
    input2.value.print_reveal_nested()
    #input1.grad.print_reveal_nested()

test_mul()
#test_add()
#test_sub()
#test_div()
#test_abs()
#test_exp()
#test_log()
#test_pow(3)

@autograd_function
def test_getitem():
    i, j = 3, 3
    x = Tensor.eye(10)

    x.print_reveal_nested()
    x[0].print_reveal_nested()
    
#test_getitem()
#test_argmax(dim=1)
#test_abs()
#test_exp()
#test_log()
#test_pow(3)
#test_invsqrt()

#test_sum([0,2])
#test_sum([0,2], keepdim=True)
#test_mean([0,2])
#test_mean([0,2,3], keepdim=True)
#test_var([0,2])
#test_var([0,2], keepdim=True)
#test_std([0,2,3])
#test_std([0,2,3], keepdim=True)


#test_addc()
#test_subc()
#test_mulc()
#test_divc()
#test_combine()
#test_neg()

#test_f_droupout(0.5)
#test_f_batchnorm()
#test_f_layernorm()
#test_f_mseloss()
#test_f_normalize(p=2, dim=[0,1])
#test_f_cossim()
#test_f_gelu()

#test_masked_fill_()
#test_gather()
test_expand()
