from tensor import Tensor,autograd_function
import tensor
import functional as F
program.options_from_args()

sfix.set_precision(30, 60)
cfix.set_precision(30, 60)

@autograd_function
def test_mul():
    print_ln('test_mul_input: ')
    x = MultiArray([3, 2, 3], sfix)
    for i in range(x.total_size()):
        x.assign_vector(sfix(i), i)
    x.print_reveal_nested()
    y = MultiArray([2, 1], sfix)
    y.assign_all(5)
    y[0][0]=6
    y.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input2 = Tensor(y, req_grad = True)

    input3 = input1 * input2

    tensor.train()
    tensor.reset_op_id()

    print_ln('test_mul_output: ')
    input3 = input1 * input2
    input3.value.print_reveal_nested()
    input3.backward()

    print_ln('test_mul_backward: ')
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()
    
def test_single_operation(func,Value):
    Value.print_reveal_nested()
    input = Tensor(Value, req_grad = True)
    output = getattr(input, func)() 
    tensor.train()
    tensor.reset_op_id()

    input3 = input1 *input2
    input3.value.print_reveal_nested()
    input3.backward()
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()

@autograd_function
def test_add():
    print_ln('test_add_input: ')
    x = MultiArray([3, 2, 3], sfix)
    for i in range(x.total_size()):
        x.assign_vector(sfix(i), i)
    x.print_reveal_nested()
    y = MultiArray([2, 1], sfix)
    y.assign_all(5)
    y[0][0]=6
    y.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input2 = Tensor(y, req_grad = True)

    input3 = input1 +input2

    tensor.train()
    tensor.reset_op_id()

    print_ln('test_add_output: ')
    input3 = input1 +input2
    input3.value.print_reveal_nested()
    input3.backward()
    print_ln('test_add_backward: ')
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()

@autograd_function
def test_sub():
    print_ln('test_sub_input: ')
    x = MultiArray([3, 3, 2], sfix)
    x.assign_all(1)
    x.print_reveal_nested()
    y = MultiArray([1, 2], sfix)
    y.assign_all(5)
    y[0][0]=6
    y.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input2 = Tensor(y, req_grad = True)

    input3 = input1 - input2

    tensor.train()
    tensor.reset_op_id()

    print_ln('test_sub_output: ')
    input3 = input1 - input2
    input3.value.print_reveal_nested()
    input3.backward()
    print_ln('test_sub_backward: ')
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()

@autograd_function
def test_div():
    print_ln('test_div_input: ')
    x = MultiArray([2, 2, 2, 2], sfix)
    y = MultiArray([1, 2, 1, 1], sfix)
    xx = [[[[-0.0150, -0.0050],
          [-0.0050,  0.0050]],

         [[-0.0162, -0.0062],
          [-0.0062,  0.0038]]],


        [[[-0.0050,  0.0050],
          [ 0.0050,  0.0150]],

         [[-0.0062,  0.0038],
          [ 0.0038,  0.0238]]]]
    yy = [[[[0.0093]],

         [[0.0119]]]]
    for i in range(0,2):
        for j in range(0,2):
            for k in range(0,2):
                for l in range(0,2):
                    x[i][j][k][l] = sfix(xx[i][j][k][l])
    for i in range(0,1):
        for j in range(0,2):
            for k in range(0,1):
                for l in range(0,1):
                    y[i][j][k][l] = sfix(yy[i][j][k][l])
    x.print_reveal_nested()
    y.print_reveal_nested()

    input1 = Tensor(x, req_grad = True)
    input2 = Tensor(y, req_grad = True)

    input3 = input1 / input2

    tensor.train()
    tensor.reset_op_id()

    print_ln('test_div_output: ')
    input3 = input1 / input2
    input3.value.print_reveal_nested()
    input3.backward()
    print_ln('test_div_backward: ')
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()

@autograd_function
def test_abs():
    print_ln('test_abs')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i-j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input2 = input1.abs()
    tensor.train()
    tensor.reset_op_id()
    input2 = input1.abs()
    input2.value.print_reveal_nested()
    input2.backward()
    input1.grad.print_reveal_nested()

@autograd_function
def test_combine():
    print_ln('test_combine')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i-j)
    xMultiArray_2_1 = MultiArray([3, 3], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            xMultiArray_2_1[i][j] = sfix(2)
    x.print_reveal_nested()
    xMultiArray_2_1.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input0 = Tensor(xMultiArray_2_1, req_grad = True)
    input8 = input1 * input0
    input2 = input8.abs()
    input3 = input2.exp()
    input4 = input3.mean()
    tensor.train()

    tensor.reset_op_id()
    input8 =  input1 * input0 
    input8.value.print_reveal_nested()
    input2 = input8.abs()
    input2.value.print_reveal_nested()
    input3 = input2.exp()
    input3.value.print_reveal_nested()
    input4 = input3.mean()
    input4.value.print_reveal_nested()    
    input4.backward()
    input1.grad.print_reveal_nested()
    input8.grad.print_reveal_nested()    
    input2.grad.print_reveal_nested()
    input3.grad.print_reveal_nested()

@autograd_function
def test_exp():
    print_ln('test_exp')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.exp()

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.exp()
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_log():
    print_ln('test_log')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.log()

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.log()
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_pow(pow):
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.pow(pow)

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.pow(pow)
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_sum(dim, keepdim=False):
    print_ln('test_sum')
    x = MultiArray([3, 3, 3, 3], sfix)
    for i in range(0,3):
        for j in range(0,3):
            for k in range(0, 3):
                for q in range(0, 3):
                    x[i][j][k][q] = sfix((i*j*k*q+i+j+k+q)*1e-2)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.sum(dim, keepdim)

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.sum(dim, keepdim)
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_mean(dim, keepdim=False):
    print_ln('test_mean')
    x = MultiArray([2, 2, 2, 2], sfix)
    for i in range(0,2):
        for j in range(0,2):
            for k in range(0, 2):
                for q in range(0, 2):
                    x[i][j][k][q] = sfix( ((i*j*k*q+i+j+k+q)%101)*1e-2)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    
    v = MultiArray([1, 2, 1, 1], sfix)
    for i in range(0,1):
        for j in range(0,2):
            for k in range(0, 1):
                for q in range(0, 1):
                    v[i][j][k][q] = sfix(i+j*10+k+q*17)
    v.assign_vector(sfix(-2100.0002), 0)
    v.assign_vector(sfix(-3721.5188), 1)
    v.print_reveal_nested()
    vec = Tensor(v, req_grad = True)

    input2 = input1.std(dim, keepdim) * vec

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.std(dim, keepdim) * vec
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_var(dim, keepdim=False):
    print_ln('test_var')
    x = MultiArray([3, 3, 3, 3], sfix)
    for i in range(0,3):
        for j in range(0,3):
            for k in range(0, 3):
                for q in range(0, 3):
                    x[i][j][k][q] = sfix((i*j*k*q+i+j+k+q)*1e-2)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.var(dim, keepdim)

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.var(dim, keepdim)
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_std(dim, keepdim=False):
    print_ln('test_std')
    x = MultiArray([2,2,2,2], sfix)
    for i in range(0,2):
        for j in range(0,2):
            for k in range(0, 2):
                for q in range(0, 2):
                    x[i][j][k][q] = sfix((i*j*k*q+i+j+k+q)%101*1e-2)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.std(dim, keepdim)

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.std(dim, keepdim)
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_addc():
    print_ln('test_addc')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1 + 1

    tensor.train()
    tensor.reset_op_id()

    input2 = input1 + 1
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_subc():
    print_ln('test_subc')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1 - 1

    tensor.train()
    tensor.reset_op_id()

    input2 = input1 - 1
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_mulc():
    print_ln('test_mulc')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1 * 2

    tensor.train()
    tensor.reset_op_id()

    input2 = input1 * 2
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_divc():
    print_ln('test_divc')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1 / 2

    tensor.train()
    tensor.reset_op_id()

    input2 = input1 / 2
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_neg():
    print_ln('test_neg')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = -input1

    tensor.train()
    tensor.reset_op_id()

    input2 = -input1
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_f_droupout(p):
    print_ln('test_droupout')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,i):
        for  j in range(0,j):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = F.dropout(input1, p=p, training=True)

    tensor.train()
    tensor.reset_op_id()

    input2 = F.dropout(input1, p=p, training=True)
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_f_batchnorm():
    print_ln('test_batchnorm')
    x = MultiArray([2,2,2,2], sfix)
    for i in range(0,2):
        for j in range(0,2):
            for k in range(0, 2):
                for q in range(0, 2):
                    x[i][j][k][q] = sfix(((i*j*k*q+i+j+k+q)%101)*1e-2)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    w, b = Array(1, sfix), Array(1, sfix)
    w[0], b[0] = sfix(1), sfix(0)
    W = Tensor(w, req_grad = True)
    B = Tensor(b, req_grad = True)

    input2, xstd, xmean = F.batch_norm(input1, weight=W, bias=B, training=True)

    v = MultiArray([2,2,2,2], sfix)
    for i in range(0,2):
        for j in range(0,2):
            for k in range(0, 2):
                for q in range(0, 2):
                    v[i][j][k][q] = sfix((i+j+k+q))
    vec = Tensor(v, req_grad = True)
    input4 = input2 * vec 

    tensor.train()
    tensor.reset_op_id()

    input2, xstd, xmean = F.batch_norm(input1, weight=W, bias=B, training=True)
    input4 = input2 * vec

    input4.backward()
    print_ln('xmean_batchnorm_output: ')
    xmean.value.print_reveal_nested()
    print_ln('xstd_batchnorm_output: ')
    xstd.value.print_reveal_nested()
    print_ln('xhat_batchnorm_output: ')
    input2.value.print_reveal_nested()
    print_ln('xhat_batchnorm_backward: ')
    input2.grad.print_reveal_nested()
    print_ln('xmean_batchnorm_backward: ')
    xmean.grad.print_reveal_nested()
    print_ln('xstd_batchnorm_backward: ')
    xstd.grad.print_reveal_nested()
    print_ln('x_batchnorm_backward: ')
    input1.grad.print_reveal_nested()

#test_mul()
#test_add()
#test_sub()
#test_div()
#test_abs()
#test_exp()
#test_log()
#test_pow(3)

@autograd_function
def test_getitem():
    i, j = 3, 3
    x = Tensor.eye(10)

    x.print_reveal_nested()
    x[0].print_reveal_nested()
    
#test_getitem()
#test_abs()
#test_exp()
#test_log()
#test_pow(3)


#test_sum([0,2])
#test_sum([0,2], keepdim=True)
#test_mean([0,2])
#test_mean([0,2,3], keepdim=True)
#test_var([0,2])
#test_var([0,2], keepdim=True)
#test_std([0,2,3])
#test_std([0,2,3], keepdim=True)


#test_addc()
#test_subc()
#test_mulc()
#test_divc()
#test_combine()
#test_neg()

#test_f_droupout(0.5)
test_f_batchnorm()