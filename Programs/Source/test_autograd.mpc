from tensor import Tensor,autograd_function
import tensor
program.options_from_args()

@autograd_function
def test_mul():
    print_ln('test_mul_input: ')
    x = MultiArray([3, 3, 2], sfix)
    x[0].assign_all(1)
    x[1].assign_all(2)
    x[2].assign_all(3)
    x.print_reveal_nested()
    y = MultiArray([1, 2], sfix)
    y.assign_all(5)
    y.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input2 = Tensor(y, req_grad = True)

    input3 = input1 * input2

    tensor.train()
    tensor.reset_op_id()

    print_ln('test_mul_output: ')
    input3 = input1 * input2
    input3.value.print_reveal_nested()
    input3.backward()
    print_ln('test_add_backward: ')
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()

def test_single_operation(func,Value):
    Value.print_reveal_nested()
    input = Tensor(Value, req_grad = True)
    output = getattr(input, func)() 
    tensor.train()
    tensor.reset_op_id()

    input3 = input1 *input2
    input3.value.print_reveal_nested()
    input3.backward()
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()

@autograd_function
def test_add():
    print_ln('test_add_input: ')
    x = MultiArray([3, 3, 2], sfix)
    x.assign_all(1)
    x.print_reveal_nested()
    y = MultiArray([1, 2], sfix)
    y.assign_all(5)
    y.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input2 = Tensor(y, req_grad = True)

    input3 = input1 +input2

    tensor.train()
    tensor.reset_op_id()

    print_ln('test_add_output: ')
    input3 = input1 +input2
    input3.value.print_reveal_nested()
    input3.backward()
    print_ln('test_add_backward: ')
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()

@autograd_function
def test_sub():
    print_ln('test_sub_input: ')
    x = MultiArray([3, 3, 2], sfix)
    x.assign_all(1)
    x.print_reveal_nested()
    y = MultiArray([1, 2], sfix)
    y.assign_all(5)
    y.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input2 = Tensor(y, req_grad = True)

    input3 = input1 - input2

    tensor.train()
    tensor.reset_op_id()

    print_ln('test_add_output: ')
    input3 = input1 - input2
    input3.value.print_reveal_nested()
    input3.backward()
    print_ln('test_add_backward: ')
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()

@autograd_function
def test_div():
    print_ln('test_div_input: ')
    x = MultiArray([3, 3, 2], sfix)
    x[0].assign_all(1)
    x[1].assign_all(2)
    x[2].assign_all(3)
    x.print_reveal_nested()
    y = MultiArray([1, 2], sfix)
    y.assign_all(5)
    y.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input2 = Tensor(y, req_grad = True)

    input3 = input1 / input2

    tensor.train()
    tensor.reset_op_id()

    print_ln('test_div_output: ')
    input3 = input1 / input2
    input3.value.print_reveal_nested()
    input3.backward()
    print_ln('test_div_backward: ')
    input1.grad.print_reveal_nested()
    input2.grad.print_reveal_nested()

@autograd_function
def test_abs():
    print_ln('test_abs')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i-j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)
    input2 = input1.abs()
    tensor.train()
    tensor.reset_op_id()
    input2 = input1.abs()
    input2.value.print_reveal_nested()
    input2.backward()
    input1.grad.print_reveal_nested()

@autograd_function
def test_exp():
    print_ln('test_exp')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.exp()

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.exp()
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_log():
    print_ln('test_log')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.log()

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.log()
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_pow(pow):
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.pow(pow)

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.pow(pow)
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_sum():
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.sum()

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.sum()
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_mean():
    print_ln('test_mean')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.mean()

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.mean()
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_var():
    print_ln('test_var')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.var()

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.var()
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_std():
    print_ln('test_std')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1.std()

    tensor.train()
    tensor.reset_op_id()

    input2 = input1.std()
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_addc():
    print_ln('test_addc')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1 + 1

    tensor.train()
    tensor.reset_op_id()

    input2 = input1 + 1
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_subc():
    print_ln('test_subc')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1 - 1

    tensor.train()
    tensor.reset_op_id()

    input2 = input1 - 1
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_mulc():
    print_ln('test_mulc')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1 * 2

    tensor.train()
    tensor.reset_op_id()

    input2 = input1 * 2
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_divc():
    print_ln('test_divc')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = input1 / 2

    tensor.train()
    tensor.reset_op_id()

    input2 = input1 / 2
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

@autograd_function
def test_neg():
    print_ln('test_neg')
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    input1 = Tensor(x, req_grad = True)

    input2 = -input1

    tensor.train()
    tensor.reset_op_id()

    input2 = -input1
    input2.backward()
    input2.value.print_reveal_nested()
    input1.grad.print_reveal_nested()

#test_mul()
#test_add()
#test_sub()
#test_div()
#test_abs()
#test_exp()
#test_log()
#test_pow(3)
#test_sum()
#test_mean()

def test_getitem():
    i, j = 3, 3
    x = MultiArray([i, j], sfix)
    for i in range(0,3):
        for  j in range(0,3):
            x[i][j] = sfix(i+j)
    x.print_reveal_nested()
    x[0].print_reveal_nested()
    
#test_getitem()
#test_abs()
#test_exp()
#test_log()
#test_pow(3)
#test_sum()
#test_mean()
#test_var()
#test_std()

#test_addc()
#test_subc()
#test_mulc()
#test_divc()

#test_neg()

x = MultiArray([3, 3, 3], sfix)
for i in range(0,3):
    for  j in range(0,3):
        for  k in range(0,3):
            x[i][j][k] = sfix(i*j+k)
x.print_reveal_nested()
x = x.mean(0)
x.print_reveal_nested()